{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2538bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff98d6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#same preprocessing as in train_def so that we have save structured data\n",
    "def count_moves(row, counts, index):\n",
    "    total_moves = 0\n",
    "    for i in range(1, 3446):\n",
    "        move = row[\"Move_\"+ str(i)]\n",
    "\n",
    "        # count the number of s's\n",
    "        if move == 's':\n",
    "            counts[10][index] += 1\n",
    "        # count the number of Base's\n",
    "        elif move == 'Base':\n",
    "            counts[11][index] += 1\n",
    "        # count the number of SingleMineral's\n",
    "        elif move == 'SingleMineral':\n",
    "            counts[12][index] += 1\n",
    "        # count the hotkeys\n",
    "        elif isinstance(move, str):\n",
    "            for j in range(10):\n",
    "                if move.startswith(f\"hotkey{j}\"):\n",
    "                    counts[j][index] += 1\n",
    "        total_moves += 1  \n",
    "    # Save the total moves count\n",
    "    counts[13][index] = total_moves\n",
    "\n",
    "\n",
    "def count_move_per_time(row, counts, row_index, time_interval, ti_index):\n",
    "    base_index = ti_index*14\n",
    "    total_moves = 0\n",
    "    for i in range(1, 3446):\n",
    "        move = row[\"Move_\" + str(i)]\n",
    "\n",
    "        # Count actions for the given time interval\n",
    "        if move == 's':\n",
    "            counts[base_index + 10][row_index] += 1\n",
    "        elif move == 'Base':\n",
    "            counts[base_index + 11][row_index] += 1\n",
    "        elif move == 'SingleMineral':\n",
    "            counts[base_index + 12][row_index] += 1\n",
    "        elif isinstance(move, str):\n",
    "            for j in range(10):\n",
    "                if move.startswith(f\"hotkey{j}\"):\n",
    "                    counts[base_index + j][row_index] += 1\n",
    "\n",
    "        total_moves += 1\n",
    "\n",
    "        # Continue counting actions after the specified time interval\n",
    "        if move == f't{time_interval}':\n",
    "            break\n",
    "\n",
    "    counts[base_index + 13][row_index] = total_moves\n",
    "\n",
    "\n",
    "def mapRaces(races, row_index):\n",
    "    race = test_data['Race'][row_index]\n",
    "\n",
    "    if race == \"Protoss\":\n",
    "        races[0][row_index] = 1\n",
    "    elif race == \"Terran\":\n",
    "        races[1][row_index] = 1\n",
    "    elif race == \"Zerg\":\n",
    "        races[2][row_index] = 1\n",
    "\n",
    "\n",
    "# Load new data file \n",
    "test_data = pd.read_csv('test_data.csv', delimiter=';')\n",
    "test_data.columns = ['Race'] + [f'Move_{i}' for i in range(1, 3446)]\n",
    "\n",
    "\n",
    "# Create new table that only contains the first column (Race) of train_data\n",
    "# Keep only the first column but all rows\n",
    "test_data_new = test_data.iloc[:, :1]\n",
    "\n",
    "# Specify the target time intervals\n",
    "#time_intervals = [20, 60, 100, 200]\n",
    "time_intervals = [5, 20, 60, 100, 200, 270, 340, 550]\n",
    "\n",
    "calc_column = len(time_intervals)* 14 + 14\n",
    "# New lists of counts\n",
    "counts = [[0] * 340 for _ in range(calc_column)]\n",
    "# New lists of races\n",
    "races = [[0] * 340 for _ in range(3)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Load the pre-trained model\n",
    "model_filename = 'player_id_prediction_model.pkl'\n",
    "clf = joblib.load(model_filename)\n",
    "\n",
    "features = test_data_new.drop(['Race'], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Use the loaded model to make predictions\n",
    "predictions = clf.predict(features)\n",
    "\n",
    "# Add predictions to the test_data_new DataFrame\n",
    "test_data_new['Predicted_PlayerID'] = predictions\n",
    "\n",
    "# print(test_data_new)\n",
    "\n",
    "\n",
    "# Load the training dataset\n",
    "train_data = pd.read_csv('train_data.csv', delimiter=';')\n",
    "\n",
    "# Extract 'PlayerID' and 'PlayerURL' columns\n",
    "player = train_data[['PlayerID', 'PlayerURL']]\n",
    "\n",
    "# take only one URL per each PlayerID\n",
    "player_info = player.drop_duplicates(subset='PlayerID', keep='first')\n",
    "\n",
    "print(player_info)\n",
    "\n",
    "# Save the result to CSV\n",
    "player_info.to_csv('player_info.csv', index=False)\n",
    "\n",
    "\n",
    "# Additional statistics if needed\n",
    "# For example, you can print the count of each predicted class\n",
    "print(\"Count of Predicted PlayerIDs:\")\n",
    "print(test_data_new['Predicted_PlayerID'].value_counts())\n",
    "\n",
    "# Extract 'Predicted_PlayerID' column\n",
    "player_id_column = test_data_new[['Predicted_PlayerID']]\n",
    "\n",
    "print(player_id_column)\n",
    "\n",
    "# Merge the predicted ID to get the url of the player\n",
    "result = pd.merge(player_id_column, player_info, left_on='Predicted_PlayerID', right_on='PlayerID', how='left')\n",
    "\n",
    "# take only the url for each player\n",
    "result = result.drop(['Predicted_PlayerID', 'PlayerID'], axis=1)\n",
    "# insert a new row in position 0 as asked for the submission and count the number of lines\n",
    "result.insert(0,\"RowId\", range(1, len(result) + 1))\n",
    "\n",
    "print(result)\n",
    "\n",
    "# Save 'PlayerURL' to CSV\n",
    "result.to_csv('player_id_only.csv', index=False)\n",
    "\n",
    "\n",
    "# Print additional statistics or analysis if needed\n",
    "print(\"Count of Unique PlayerURLs:\")\n",
    "print(result['PlayerURL'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aab0ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go through the rows using the functions to count the actions, map the races\n",
    "for row_index, row in test_data.iterrows():\n",
    "    count_moves(row, counts, row_index)\n",
    "    mapRaces(races, row_index)\n",
    "\n",
    "    for ti_index, time_interval in enumerate(time_intervals):\n",
    "        count_move_per_time(row, counts, row_index, time_interval, ti_index+1)\n",
    "\n",
    "# Adding all the new columns to the train_data_new\n",
    "# Adding new columns for the count of moves\n",
    "for i in range(calc_column):\n",
    "    locals()[f'count_{i}'] = counts[i]\n",
    "\n",
    "for i in range(10):\n",
    "    test_data_new[f'hk{i}Frequency'] = [count / counts[13][index] if counts[13][index] != 0 else 0 for index, count in enumerate(counts[i])]\n",
    "\n",
    "test_data_new['sFrequency'] = [count / counts[13][index] if counts[13][index] != 0 else 0 for index, count in enumerate(counts[10])]\n",
    "test_data_new['baseFrequency'] = [count / counts[13][index] if counts[13][index] != 0 else 0 for index, count in enumerate(counts[11])]\n",
    "test_data_new['singleMineralFrequency'] = [count / counts[13][index] if counts[13][index] != 0 else 0 for index, count in enumerate(counts[12])]\n",
    "\n",
    "# Adding new columns for the count of moves per interval\n",
    "for ti_index, time_interval in enumerate(time_intervals):\n",
    "    base_index = (ti_index + 1) * 14\n",
    "    for j in range(10):\n",
    "        column_name = f'hk{j}_t{time_interval}_Frequency'\n",
    "        test_data_new[column_name] = [count / counts[base_index + 13][index] if counts[base_index + 13][index] != 0 else 0 for index, count in enumerate(counts[base_index + j])]\n",
    "\n",
    "    test_data_new[f's_t{time_interval}_Frequency'] = [count / counts[base_index + 13][index] if counts[base_index + 13][index] != 0 else 0 for index, count in enumerate(counts[base_index + 10])]\n",
    "    test_data_new[f'base_t{time_interval}_Frequency'] = [count / counts[base_index + 13][index] if counts[base_index + 13][index] != 0 else 0 for index, count in enumerate(counts[base_index + 11])]\n",
    "    test_data_new[f'singleMineral_t{time_interval}_Frequency'] = [count / counts[base_index + 13][index] if counts[base_index + 13][index] != 0 else 0 for index, count in enumerate(counts[base_index + 12])]\n",
    "\n",
    "\n",
    "\n",
    "# Adding new columns for the races\n",
    "test_data_new['race_Protoss'] = races[0]\n",
    "test_data_new['race_Terran'] = races[1]\n",
    "test_data_new['race_Zerg'] = races[2]\n",
    "\n",
    "\n",
    "# Saving thhem in a csv file\n",
    "test_data_new.to_csv('actiontype_count_test.csv', index=False)\n",
    "\n",
    "test_data_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9da46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the first row of the features DataFrame (for the first prediction)\n",
    "first_row_features = features.iloc[[30]]\n",
    "\n",
    "# Use the loaded model to get the feature importances for the first prediction\n",
    "prediction_feature_importances = clf.feature_importances_\n",
    "\n",
    "# Create a DataFrame to store feature names and their importances\n",
    "prediction_feature_importance_df = pd.DataFrame({\n",
    "    'Feature': first_row_features.columns,\n",
    "    'Importance': prediction_feature_importances\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by importance in descending order\n",
    "prediction_feature_importance_df = prediction_feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(40, 32))\n",
    "plt.barh(prediction_feature_importance_df['Feature'], prediction_feature_importance_df['Importance'], color='skyblue')\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Feature Importances for the Second Prediction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f64e4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances from the trained Random Forest classifier\n",
    "feature_importances = clf.feature_importances_\n",
    "\n",
    "# Create a DataFrame with feature names and their importances\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': features.columns,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "# Sort features by importance in descending order\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Plotting the top features\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'], color='skyblue')\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Top Features Importance')\n",
    "plt.show()\n",
    "\n",
    "# Calculate the threshold for the 30% least important features\n",
    "threshold = feature_importance_df['Importance'].quantile(0.3)\n",
    "\n",
    "# Get the least important features\n",
    "least_important_features = feature_importance_df[feature_importance_df['Importance'] < threshold]['Feature'].tolist()\n",
    "\n",
    "# Print the least important features\n",
    "print(\"Least Important Features (30%):\")\n",
    "print(least_important_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bdeaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your RandomForestClassifier is named 'clf'\n",
    "feature_importances = clf.feature_importances_\n",
    "\n",
    "# Create a DataFrame with feature names and their importance scores\n",
    "feature_importance_df = pd.DataFrame({'Feature': features.columns, 'Importance': feature_importances})\n",
    "\n",
    "# Filter features with importance less than 0.01\n",
    "less_important_features = feature_importance_df[feature_importance_df['Importance'] < 0.0075]['Feature'].tolist()\n",
    "\n",
    "# Display or use the list of less important features\n",
    "print(\"Less Important Features:\")\n",
    "print(less_important_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
