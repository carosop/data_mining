{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bf9faad",
   "metadata": {},
   "source": [
    "# Data Mining - StarCraft Player Prediction\n",
    "\n",
    "The goal of the project was it to predict which player is playing a certain game based on the moves he or she made."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900248a1",
   "metadata": {},
   "source": [
    "## Pre-processing Training Data\n",
    "\n",
    "To train a model we were given data where each row represented a gameplay. A row included information about the race, the player who was playing and the moves he or she made during the game. \n",
    "Before starting with the classification algorithms we had to find a way to process our data and make it comparable. We wanted to reduce dimensions without losing information. In order to do so we started counting how often a player would use a certain move. We did this over the course of a whole game and also over the course of certain time periods\n",
    "\n",
    "We then realised this was not very meaningful. How often a player presses a certain key does not make him or her recognizable. So we decided to focus on frequency of moves. Meaning how frequent a player was using certain moves. Overall and again also over the course of certain time periods. To standardize the data we also created three new columns that mapped the name of the race (which was of type string before) to a zero or a one. Depending on whether this particular race was being played or not. \n",
    "Of course, preprocessing also included deleting unnecessary columns like Player URL and Player Name.\n",
    "\n",
    "1. based on the amount of moves\n",
    "2. frequency (also mention the mapping of the races)\n",
    "3. started with unique sequences in the first 10 seconds\n",
    "\n",
    "By analysing our train dataset, we realised that the same player uses typically the same sequence of moves, for a certain race type, in the first 10 seconds with slight variations. So we wanted to find a unique sequence for each player that immediatly identified him by the use of a specific combination of moves, for a specific type of race played. \n",
    "We started working on this idea by creating a function for the research of consecutive sequences of moves, excluding the time data,'t5' and 't10' and iterate the process for each player to find the action sequences.\n",
    "At the end we saved the found sequences to a text file.\n",
    "We proceeded by defining a function to evaluate the combination of sequences based on their uniqueness, and applyed to each player to obtain ranked combinations.\n",
    "At this point we stopped as we realised that we should create a training model that find the best sequence of actions for each player based on the ranking and then combine this model with others, as Randomforest, in order to predict in the most accurate way the player based also on the total time of the race and on other features.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742788d7",
   "metadata": {},
   "source": [
    "## Choosing a model\n",
    "\n",
    "(also mention the f1 accuracy, cross-validation)\n",
    "\n",
    "1. TreeClassifier\n",
    "2. Random Forest\n",
    "3. Random Forest + GridSearch\n",
    "3. + Feature Importance [Link Text](/Feature Importance.ipynb)\n",
    "4. + AdaBoost\n",
    "5. + Voting / Stacking Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14afbfd1",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "When given the test data we were looking at almost the same pattern as the training data: Each row was a gameplay with a race and the moves made. Just the identifaction of the player was missing. That one was for us to predict and to do so we used our pretrained model. \n",
    "\n",
    "### Precossesing\n",
    "\n",
    "But before, we had to change the data in the same way we did with the training data. We did this, so they would be able to compare.\n",
    "\n",
    "### Predicting \n",
    "\n",
    "The pre-trained model was then loaded and used to make predictions about the players.\n",
    "\n",
    "- Same preprocessing as training data to make it comparable\n",
    "- used pretrained model\n",
    "\n",
    "Afterwards we added some statistics to asses the testing performance. We wanted to see which predictions were made: ...\n",
    "\n",
    "And how many different players were predicted. We increased this score over time, because it meant our model was able differentiate better between players.\n",
    "\n",
    "- how many different players were predicted. we want a higher score because it can differentiate \n",
    "\n",
    "At the end we merged the predicted player IDs with the first row of the training data to obtain the corresponding player URLs.\n",
    "- Merge the predicted ID to get the url of the player"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79879abb",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "With our model we managed to reach a level of 82% testing accuracy and 92% training accuracy. \n",
    "\n",
    "- training and testing accuracy not always the same\n",
    "- \n",
    "\n",
    "### Improvements\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
