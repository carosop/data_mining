{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46b74f81",
   "metadata": {},
   "source": [
    "comments: \n",
    "    - count moves without frequency is missing\n",
    "    - sequence code does not work yet\n",
    "    - link notebook to feature importance is missing\n",
    "    - finish choose a model, testing and results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf9faad",
   "metadata": {},
   "source": [
    "# Data Mining - StarCraft Player Prediction\n",
    "\n",
    "The goal of the project was it to predict which player is playing a certain game based on the moves he or she made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "144bfe14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "import joblib\n",
    "import warnings\n",
    "# Suppress all warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1cbede",
   "metadata": {},
   "source": [
    "## Pre-processing Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900248a1",
   "metadata": {},
   "source": [
    "To train a model we were given data where each row represented a gameplay. A row included information about the race, the player who was playing and the moves he or she made during the game. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ad9f948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PlayerID</th>\n",
       "      <th>Race</th>\n",
       "      <th>Move 1</th>\n",
       "      <th>Move 2</th>\n",
       "      <th>Move 3</th>\n",
       "      <th>Move 4</th>\n",
       "      <th>Move 5</th>\n",
       "      <th>Move 6</th>\n",
       "      <th>Move 7</th>\n",
       "      <th>Move 8</th>\n",
       "      <th>...</th>\n",
       "      <th>Move 2554</th>\n",
       "      <th>Move 2555</th>\n",
       "      <th>Move 2556</th>\n",
       "      <th>Move 2557</th>\n",
       "      <th>Move 2558</th>\n",
       "      <th>Move 2559</th>\n",
       "      <th>Move 2560</th>\n",
       "      <th>Move 2561</th>\n",
       "      <th>Move 2562</th>\n",
       "      <th>Move 2563</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1021189</td>\n",
       "      <td>Terran</td>\n",
       "      <td>s</td>\n",
       "      <td>hotkey11</td>\n",
       "      <td>hotkey21</td>\n",
       "      <td>hotkey31</td>\n",
       "      <td>hotkey41</td>\n",
       "      <td>hotkey51</td>\n",
       "      <td>hotkey61</td>\n",
       "      <td>s</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1021189</td>\n",
       "      <td>Terran</td>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>hotkey11</td>\n",
       "      <td>hotkey21</td>\n",
       "      <td>hotkey31</td>\n",
       "      <td>hotkey41</td>\n",
       "      <td>hotkey51</td>\n",
       "      <td>hotkey61</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1021189</td>\n",
       "      <td>Terran</td>\n",
       "      <td>s</td>\n",
       "      <td>hotkey11</td>\n",
       "      <td>hotkey21</td>\n",
       "      <td>hotkey31</td>\n",
       "      <td>hotkey41</td>\n",
       "      <td>hotkey51</td>\n",
       "      <td>hotkey61</td>\n",
       "      <td>hotkey71</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1021189</td>\n",
       "      <td>Terran</td>\n",
       "      <td>s</td>\n",
       "      <td>hotkey11</td>\n",
       "      <td>hotkey21</td>\n",
       "      <td>hotkey31</td>\n",
       "      <td>hotkey41</td>\n",
       "      <td>hotkey51</td>\n",
       "      <td>hotkey61</td>\n",
       "      <td>t5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1021189</td>\n",
       "      <td>Terran</td>\n",
       "      <td>s</td>\n",
       "      <td>hotkey11</td>\n",
       "      <td>hotkey21</td>\n",
       "      <td>hotkey31</td>\n",
       "      <td>hotkey41</td>\n",
       "      <td>hotkey51</td>\n",
       "      <td>hotkey71</td>\n",
       "      <td>hotkey61</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2565 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PlayerID    Race Move 1    Move 2    Move 3    Move 4    Move 5    Move 6  \\\n",
       "0   1021189  Terran      s  hotkey11  hotkey21  hotkey31  hotkey41  hotkey51   \n",
       "1   1021189  Terran      s         s  hotkey11  hotkey21  hotkey31  hotkey41   \n",
       "2   1021189  Terran      s  hotkey11  hotkey21  hotkey31  hotkey41  hotkey51   \n",
       "3   1021189  Terran      s  hotkey11  hotkey21  hotkey31  hotkey41  hotkey51   \n",
       "4   1021189  Terran      s  hotkey11  hotkey21  hotkey31  hotkey41  hotkey51   \n",
       "\n",
       "     Move 7    Move 8  ... Move 2554 Move 2555 Move 2556 Move 2557 Move 2558  \\\n",
       "0  hotkey61         s  ...       NaN       NaN       NaN       NaN       NaN   \n",
       "1  hotkey51  hotkey61  ...       NaN       NaN       NaN       NaN       NaN   \n",
       "2  hotkey61  hotkey71  ...       NaN       NaN       NaN       NaN       NaN   \n",
       "3  hotkey61        t5  ...       NaN       NaN       NaN       NaN       NaN   \n",
       "4  hotkey71  hotkey61  ...       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "  Move 2559 Move 2560 Move 2561 Move 2562 Move 2563  \n",
       "0       NaN       NaN       NaN       NaN       NaN  \n",
       "1       NaN       NaN       NaN       NaN       NaN  \n",
       "2       NaN       NaN       NaN       NaN       NaN  \n",
       "3       NaN       NaN       NaN       NaN       NaN  \n",
       "4       NaN       NaN       NaN       NaN       NaN  \n",
       "\n",
       "[5 rows x 2565 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the training dataset\n",
    "train_data = pd.read_csv('train_data.csv', delimiter=';')\n",
    "\n",
    "# Drop unnecessary columns\n",
    "train_data = train_data.drop(['PlayerURL', 'PlayerName'], axis=1)\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c6becb",
   "metadata": {},
   "source": [
    "Before starting with the classification algorithms we had to find a way to process our data and make it comparable. We wanted to reduce dimensions without losing information. In order to do so, we started counting how often a player would use a certain move. We did this over the course of a whole game and also over the course of certain time periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f813217",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'count_moves' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Go through the rows using the functions to count the actions, map the races\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row_index, row \u001b[38;5;129;01min\u001b[39;00m train_data\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m---> 20\u001b[0m     \u001b[43mcount_moves\u001b[49m(row, counts, row_index)\n\u001b[0;32m     21\u001b[0m     mapRaces(races, row_index)\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ti_index, time_interval \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(time_intervals):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'count_moves' is not defined"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "\n",
    "# Create new table that only contains the first column (PlayerId) of train_data\n",
    "# Keep only the first column but all rows\n",
    "train_data_new = train_data.iloc[:, :1]\n",
    "\n",
    "# Specify the target time intervals\n",
    "#time_intervals = [20, 60, 100, 200]\n",
    "time_intervals = [5, 20, 60, 100, 200, 270, 340, 550]\n",
    "\n",
    "calc_column = len(time_intervals)* 14 + 14\n",
    "\n",
    "# New lists of counts\n",
    "counts = [[0] * 3052 for _ in range(calc_column)]\n",
    "# New lists of races\n",
    "races = [[0] * 3052 for _ in range(3)]\n",
    "\n",
    "# Go through the rows using the functions to count the actions, map the races\n",
    "for row_index, row in train_data.iterrows():\n",
    "    count_moves(row, counts, row_index)\n",
    "    mapRaces(races, row_index)\n",
    "\n",
    "    for ti_index, time_interval in enumerate(time_intervals):\n",
    "        count_move_per_time(row, counts, row_index, time_interval, ti_index+1)\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6cb647",
   "metadata": {},
   "source": [
    "We then realised this was not very meaningful. How often a player presses a certain key, does not make him or her recognizable. So we decided to focus on frequency of moves. Meaning how frequent a player was using certain moves. Overall and again also over the course of certain time periods. To standardize the data we also created three new columns that mapped the name of the race (which was of type string before) to a zero or a one. Depending on whether this particular race was being played or not. \n",
    "Of course, preprocessing also included deleting unnecessary columns like Player URL and Player Name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4c25f69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PlayerID</th>\n",
       "      <th>hk0Frequency</th>\n",
       "      <th>hk1Frequency</th>\n",
       "      <th>hk2Frequency</th>\n",
       "      <th>hk3Frequency</th>\n",
       "      <th>hk4Frequency</th>\n",
       "      <th>hk5Frequency</th>\n",
       "      <th>hk6Frequency</th>\n",
       "      <th>hk7Frequency</th>\n",
       "      <th>hk8Frequency</th>\n",
       "      <th>...</th>\n",
       "      <th>hk6_t550_Frequency</th>\n",
       "      <th>hk7_t550_Frequency</th>\n",
       "      <th>hk8_t550_Frequency</th>\n",
       "      <th>hk9_t550_Frequency</th>\n",
       "      <th>s_t550_Frequency</th>\n",
       "      <th>base_t550_Frequency</th>\n",
       "      <th>singleMineral_t550_Frequency</th>\n",
       "      <th>race_Protoss</th>\n",
       "      <th>race_Terran</th>\n",
       "      <th>race_Zerg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1021189</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.158018</td>\n",
       "      <td>0.107296</td>\n",
       "      <td>0.032384</td>\n",
       "      <td>0.030043</td>\n",
       "      <td>0.007803</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000994</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.407555</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000994</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1021189</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.149044</td>\n",
       "      <td>0.062037</td>\n",
       "      <td>0.055014</td>\n",
       "      <td>0.017167</td>\n",
       "      <td>0.001951</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000853</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.320546</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1021189</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.130316</td>\n",
       "      <td>0.086617</td>\n",
       "      <td>0.018728</td>\n",
       "      <td>0.030823</td>\n",
       "      <td>0.006243</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>0.00039</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001289</td>\n",
       "      <td>0.001289</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.389175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002577</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1021189</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166602</td>\n",
       "      <td>0.120562</td>\n",
       "      <td>0.033554</td>\n",
       "      <td>0.044479</td>\n",
       "      <td>0.021459</td>\n",
       "      <td>0.001171</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000971</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.350485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000971</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1021189</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.154506</td>\n",
       "      <td>0.077253</td>\n",
       "      <td>0.022630</td>\n",
       "      <td>0.041748</td>\n",
       "      <td>0.010925</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>0.00039</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001104</td>\n",
       "      <td>0.001104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.429360</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002208</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 121 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PlayerID  hk0Frequency  hk1Frequency  hk2Frequency  hk3Frequency  \\\n",
       "0   1021189           0.0      0.158018      0.107296      0.032384   \n",
       "1   1021189           0.0      0.149044      0.062037      0.055014   \n",
       "2   1021189           0.0      0.130316      0.086617      0.018728   \n",
       "3   1021189           0.0      0.166602      0.120562      0.033554   \n",
       "4   1021189           0.0      0.154506      0.077253      0.022630   \n",
       "\n",
       "   hk4Frequency  hk5Frequency  hk6Frequency  hk7Frequency  hk8Frequency  ...  \\\n",
       "0      0.030043      0.007803      0.000390       0.00000           0.0  ...   \n",
       "1      0.017167      0.001951      0.000390       0.00000           0.0  ...   \n",
       "2      0.030823      0.006243      0.000390       0.00039           0.0  ...   \n",
       "3      0.044479      0.021459      0.001171       0.00000           0.0  ...   \n",
       "4      0.041748      0.010925      0.000390       0.00039           0.0  ...   \n",
       "\n",
       "   hk6_t550_Frequency  hk7_t550_Frequency  hk8_t550_Frequency  \\\n",
       "0            0.000994            0.000000                 0.0   \n",
       "1            0.000853            0.000000                 0.0   \n",
       "2            0.001289            0.001289                 0.0   \n",
       "3            0.000971            0.000000                 0.0   \n",
       "4            0.001104            0.001104                 0.0   \n",
       "\n",
       "   hk9_t550_Frequency  s_t550_Frequency  base_t550_Frequency  \\\n",
       "0                 0.0          0.407555                  0.0   \n",
       "1                 0.0          0.320546                  0.0   \n",
       "2                 0.0          0.389175                  0.0   \n",
       "3                 0.0          0.350485                  0.0   \n",
       "4                 0.0          0.429360                  0.0   \n",
       "\n",
       "   singleMineral_t550_Frequency  race_Protoss  race_Terran  race_Zerg  \n",
       "0                      0.000994             0            1          0  \n",
       "1                      0.000000             0            1          0  \n",
       "2                      0.002577             0            1          0  \n",
       "3                      0.000971             0            1          0  \n",
       "4                      0.002208             0            1          0  \n",
       "\n",
       "[5 rows x 121 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_moves(row, counts, index):\n",
    "    total_moves = 0\n",
    "    for i in range(1, 2564):\n",
    "        move = row[\"Move \"+ str(i)]\n",
    "        # count the number of s's\n",
    "        if move == 's':\n",
    "            counts[10][index] += 1\n",
    "        # count the number of Base's\n",
    "        elif move == 'Base':\n",
    "            counts[11][index] += 1\n",
    "        # count the number of SingleMineral's\n",
    "        elif move == 'SingleMineral':\n",
    "            counts[12][index] += 1\n",
    "        # count the hotkeys\n",
    "        elif isinstance(move, str):\n",
    "            for j in range(10):\n",
    "                if move.startswith(f\"hotkey{j}\"):\n",
    "                    counts[j][index] += 1\n",
    "\n",
    "        total_moves += 1  \n",
    "    # Save the total moves count\n",
    "    counts[13][index] = total_moves\n",
    "\n",
    "\n",
    "def count_move_per_time(row, counts, row_index, time_interval, ti_index):\n",
    "    base_index = ti_index * 14\n",
    "    total_moves = 0\n",
    "\n",
    "    for i in range(1, 2564):\n",
    "        move = row[\"Move \" + str(i)]\n",
    "\n",
    "        # Count actions for the given time interval\n",
    "        if move == 's':\n",
    "            counts[base_index + 10][row_index] += 1\n",
    "        elif move == 'Base':\n",
    "            counts[base_index + 11][row_index] += 1\n",
    "        elif move == 'SingleMineral':\n",
    "            counts[base_index + 12][row_index] += 1\n",
    "        elif isinstance(move, str):\n",
    "            for j in range(10):\n",
    "                if move.startswith(f\"hotkey{j}\"):\n",
    "                    counts[base_index + j][row_index] += 1\n",
    "\n",
    "        total_moves += 1\n",
    "\n",
    "        # Continue counting actions after the specified time interval\n",
    "        if move == f't{time_interval}':\n",
    "            break\n",
    "\n",
    "    counts[base_index + 13][row_index] = total_moves\n",
    "\n",
    "\n",
    "def mapRaces(races, row_index):\n",
    "    race = train_data['Race'][row_index]\n",
    "\n",
    "    if race == \"Protoss\":\n",
    "        races[0][row_index] = 1\n",
    "    elif race == \"Terran\":\n",
    "        races[1][row_index] = 1\n",
    "    elif race == \"Zerg\":\n",
    "        races[2][row_index] = 1\n",
    "        \n",
    "# Create new table that only contains the first column (PlayerId) of train_data\n",
    "# Keep only the first column but all rows\n",
    "train_data_new = train_data.iloc[:, :1]\n",
    "\n",
    "\n",
    "# Specify the target time intervals\n",
    "#time_intervals = [20, 60, 100, 200]\n",
    "time_intervals = [5, 20, 60, 100, 200, 270, 340, 550]\n",
    "\n",
    "calc_column = len(time_intervals)* 14 + 14\n",
    "\n",
    "# New lists of counts\n",
    "counts = [[0] * 3052 for _ in range(calc_column)]\n",
    "# New lists of races\n",
    "races = [[0] * 3052 for _ in range(3)]\n",
    "\n",
    "\n",
    "# Go through the rows using the functions to count the actions, map the races\n",
    "for row_index, row in train_data.iterrows():\n",
    "    count_moves(row, counts, row_index)\n",
    "    mapRaces(races, row_index)\n",
    "\n",
    "    for ti_index, time_interval in enumerate(time_intervals):\n",
    "        count_move_per_time(row, counts, row_index, time_interval, ti_index+1)\n",
    "        \n",
    "\n",
    "for i in range(calc_column):\n",
    "    locals()[f'count_{i}'] = counts[i]\n",
    "\n",
    "for i in range(10):\n",
    "    train_data_new[f'hk{i}Frequency'] = [count / counts[13][index] if counts[13][index] != 0 else 0 for index, count in enumerate(counts[i])]\n",
    "\n",
    "train_data_new['sFrequency'] = [count / counts[13][index] if counts[13][index] != 0 else 0 for index, count in enumerate(counts[10])]\n",
    "train_data_new['baseFrequency'] = [count / counts[13][index] if counts[13][index] != 0 else 0 for index, count in enumerate(counts[11])]\n",
    "train_data_new['singleMineralFrequency'] = [count / counts[13][index] if counts[13][index] != 0 else 0 for index, count in enumerate(counts[12])]\n",
    "\n",
    "# Adding new columns for the count of moves per interval\n",
    "for ti_index, time_interval in enumerate(time_intervals):\n",
    "    base_index = (ti_index + 1) * 14\n",
    "    for j in range(10):\n",
    "        column_name = f'hk{j}_t{time_interval}_Frequency'\n",
    "        train_data_new[column_name] = [count / counts[base_index + 13][index] if counts[base_index + 13][index] != 0 else 0 for index, count in enumerate(counts[base_index + j])]\n",
    "\n",
    "    train_data_new[f's_t{time_interval}_Frequency'] = [count / counts[base_index + 13][index] if counts[base_index + 13][index] != 0 else 0 for index, count in enumerate(counts[base_index + 10])]\n",
    "    train_data_new[f'base_t{time_interval}_Frequency'] = [count / counts[base_index + 13][index] if counts[base_index + 13][index] != 0 else 0 for index, count in enumerate(counts[base_index + 11])]\n",
    "    train_data_new[f'singleMineral_t{time_interval}_Frequency'] = [count / counts[base_index + 13][index] if counts[base_index + 13][index] != 0 else 0 for index, count in enumerate(counts[base_index + 12])]\n",
    "\n",
    "\n",
    "\n",
    "# Adding new columns for the races\n",
    "train_data_new['race_Protoss'] = races[0]\n",
    "train_data_new['race_Terran'] = races[1]\n",
    "train_data_new['race_Zerg'] = races[2]\n",
    "\n",
    "# Saving them in a csv file\n",
    "train_data_new.to_csv('actiontype_count.csv', index=False)\n",
    "\n",
    "train_data_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3003b8",
   "metadata": {},
   "source": [
    "By analysing our train dataset, we realised that the same player uses typically the same sequence of moves, for a certain race type, in the first 10 seconds with slight variations. So we wanted to find a unique sequence for each player that immediately identified him by the use of a specific combination of moves, for a specific type of race played. \n",
    "We started working on this idea by creating a function for the research of consecutive sequences of moves, excluding the time data,'t5' and 't10' and iterate the process for each player to find the action sequences.\n",
    "At the end we saved the found sequences to a text file.\n",
    "We proceeded by defining a function to evaluate the combination of sequences based on their uniqueness, and applied to each player to obtain ranked combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6df23963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moves Frequency:\n",
      "hotkey11: 20\n",
      "hotkey21: 41\n",
      "hotkey31: 20\n",
      "hotkey41: 54\n",
      "hotkey51: 23\n",
      "hotkey61: 43\n",
      "s: 25854\n",
      "SingleMineral: 540\n",
      "t5: 3041\n",
      "hotkey12: 5676\n",
      "hotkey22: 4988\n",
      "t10: 3039\n",
      "hotkey30: 1529\n",
      "hotkey71: 27\n",
      "hotkey32: 3827\n",
      "hotkey20: 1957\n",
      "hotkey40: 1336\n",
      "hotkey10: 1844\n",
      "hotkey90: 643\n",
      "hotkey70: 488\n",
      "hotkey80: 488\n",
      "hotkey42: 4564\n",
      "hotkey00: 881\n",
      "hotkey50: 986\n",
      "hotkey52: 2903\n",
      "Base: 1920\n",
      "hotkey81: 19\n",
      "hotkey91: 56\n",
      "hotkey01: 81\n",
      "hotkey60: 654\n",
      "hotkey62: 1120\n",
      "hotkey92: 261\n",
      "hotkey82: 94\n",
      "hotkey02: 503\n",
      "hotkey72: 67\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'groupby' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 65\u001b[0m\n\u001b[0;32m     63\u001b[0m player_sequences \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m player, moves \u001b[38;5;129;01min\u001b[39;00m grouped_data\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m---> 65\u001b[0m     sequences \u001b[38;5;241m=\u001b[39m \u001b[43mfind_sequences\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmoves\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m     player_sequences[player] \u001b[38;5;241m=\u001b[39m sequences\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# Save the found sequences to a text file\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[5], line 53\u001b[0m, in \u001b[0;36mfind_sequences\u001b[1;34m(group)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_sequences\u001b[39m(group):\n\u001b[0;32m     52\u001b[0m     sequences \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 53\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, g \u001b[38;5;129;01min\u001b[39;00m \u001b[43mgroupby\u001b[49m(\u001b[38;5;28menumerate\u001b[39m(group), key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mint\u001b[39m(x[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt10\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[0;32m     54\u001b[0m         consecutive_moves \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m1\u001b[39m], g))\n\u001b[0;32m     56\u001b[0m         \u001b[38;5;66;03m# Remove 't5' and 't10' from consecutive_moves\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'groupby' is not defined"
     ]
    }
   ],
   "source": [
    "# Get the indices for columns 'Move_1' to 'Move_50'\n",
    "move_columns = [f'Move_{i}' for i in range(1, 68)]\n",
    "\n",
    "data_10s = []\n",
    "\n",
    "# Iterate through each row of the dataframe\n",
    "for _, row in train_data.iterrows():\n",
    "    row_actions = []\n",
    "\n",
    "    # Iterate through each 'Move_XX' column for the current row\n",
    "    for col in train_data.columns[3:70]:\n",
    "        row_actions.append(row[col])\n",
    "\n",
    "        # Check if the current action is 't10'\n",
    "        if row[col] == 't10':  # Assuming 't10' is converted to 100 in your previous processing\n",
    "            break  # Stop iterating if 't10' is found\n",
    "\n",
    "    data_10s.append(row_actions)\n",
    "\n",
    "# Convert the result to a new dataframe if needed\n",
    "data_10s_df = pd.DataFrame(data_10s, columns=move_columns)\n",
    "\n",
    "data_10s_df.insert(0, 'PlayerID', train_data['PlayerID'])\n",
    "data_10s_df.insert(1, 'Race', train_data['Race'])\n",
    "\n",
    "data_10s_df.to_csv('data_10s.csv', index=False)\n",
    "\n",
    "# Load the data_10s.csv file\n",
    "data_10s_df = pd.read_csv('data_10s.csv')\n",
    "\n",
    "# Get the move columns\n",
    "move_columns = [f'Move_{i}' for i in range(1, 68)]\n",
    "\n",
    "# Flatten the dataframe to have a single column of moves\n",
    "all_moves = data_10s_df[move_columns].values.flatten()\n",
    "\n",
    "# Count the frequency of each move\n",
    "moves_frequency = {}\n",
    "for move in all_moves:\n",
    "    if pd.notna(move):  # Exclude NaN values\n",
    "        moves_frequency[move] = moves_frequency.get(move, 0) + 1\n",
    "\n",
    "print(\"Moves Frequency:\")\n",
    "for move, frequency in moves_frequency.items():\n",
    "    print(f\"{move}: {frequency}\")\n",
    "\n",
    "# Group the data by PlayerID and reset the index\n",
    "grouped_data = data_10s_df.groupby('PlayerID')[move_columns].apply(lambda x: x.reset_index(drop=True))\n",
    "\n",
    "# Define a function to find sequences of consecutive moves\n",
    "def find_sequences(group):\n",
    "    sequences = []\n",
    "    for _, g in groupby(enumerate(group), key=lambda x: int(x[1] == 't10')):\n",
    "        consecutive_moves = list(map(lambda x: x[1], g))\n",
    "\n",
    "        # Remove 't5' and 't10' from consecutive_moves\n",
    "        consecutive_moves = [move for move in consecutive_moves if move not in ['t5', 't10']]\n",
    "\n",
    "        sequences.append(consecutive_moves)\n",
    "    return sequences\n",
    "\n",
    "# Iterate through each player's moves and find sequences\n",
    "player_sequences = {}\n",
    "for player, moves in grouped_data.iterrows():\n",
    "    sequences = find_sequences(moves.dropna().astype(str))\n",
    "    player_sequences[player] = sequences\n",
    "\n",
    "# Save the found sequences to a text file\n",
    "output_file_path = 'sequences.txt'\n",
    "with open(output_file_path, 'w') as file:\n",
    "    for player, sequences in player_sequences.items():\n",
    "        file.write(f\"{player} : \\t\")\n",
    "        for sequence in sequences:\n",
    "            file.write(','.join(sequence) + '\\n')\n",
    "        file.write(\"\\n\")\n",
    "\n",
    "print(f\"Sequences saved to {output_file_path}\")\n",
    "\n",
    "# Define a function to evaluate the combination of moves\n",
    "def evaluate_combination(combination):\n",
    "    unique_moves = set(combination[0] + combination[1])\n",
    "    uniqueness_score = sum(moves_frequency.get(move, 0) for move in unique_moves)\n",
    "    return uniqueness_score\n",
    "\n",
    "# Iterate through each player's sequences and find ranked combinations\n",
    "ranked_combinations = {}\n",
    "for player, sequences in player_sequences.items():\n",
    "    combinations_list = list(combinations(sequences, 2))\n",
    "    ranked_combinations[player] = sorted(combinations_list, key=lambda x: evaluate_combination(x), reverse=True)\n",
    "\n",
    "# Print or save the ranked combinations\n",
    "for player, combinations in ranked_combinations.items():\n",
    "    print(f\"Player {player} ranked combinations:\")\n",
    "    for i, combination in enumerate(combinations, start=1):\n",
    "        print(f\"Rank {i}: {combination} - Score: {evaluate_combination(combination)}\")\n",
    "\n",
    "# Save the ranked combinations to a text file\n",
    "output_file_path = 'ranked_combinations.txt'\n",
    "with open(output_file_path, 'w') as file:\n",
    "    for player, combinations in ranked_combinations.items():\n",
    "        file.write(f\"Player {player} ranked combinations:\\n\")\n",
    "        for i, combination in enumerate(combinations, start=1):\n",
    "            file.write(f\"Rank {i}: {combination} - Score: {evaluate_combination(combination)}\\n\")\n",
    "        file.write(\"\\n\")\n",
    "\n",
    "print(f\"Ranked combinations saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db880b8",
   "metadata": {},
   "source": [
    "At this point we stopped as we realised that we should create a training model that find the best sequence of actions for each player based on the ranking and then combine this model with others, as RandomForest, in order to predict in the most accurate way the player based also on the total time of the race and on other features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742788d7",
   "metadata": {},
   "source": [
    "## Choosing a model\n",
    "\n",
    "Choosing the right model is crucial, because it directly influences the accuracy of the predictions and therefor impacts the overall success and reliability of our system. We will evaluate the different models we tried by using the F1 accuracy and cross-validation.\n",
    "\n",
    "1. TreeClassifier\n",
    "2. Random Forest\n",
    "3. Random Forest + GridSearch\n",
    "3. + Feature Importance [Link Text](/Feature Importance.ipynb)\n",
    "4. + AdaBoost\n",
    "5. + Voting / Stacking Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6806f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target\n",
    "labels = train_data_new['PlayerID']\n",
    "\n",
    "# Keep only the columns we need as features\n",
    "features = train_data_new.drop(['PlayerID'], axis=1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(features, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7505a988",
   "metadata": {},
   "source": [
    "We started by using the TreeClassifier. This gave us a training accuracy of 76%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05154e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7610474631751227\n",
      "F1 Score on Validation Set: 0.7610474631751227\n",
      "Cross Validation Scores: [0.7051114  0.77588467 0.78505898 0.72608126]\n"
     ]
    }
   ],
   "source": [
    "# Choose Decision Tree as a model and train it\n",
    "model = DecisionTreeClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions on the val set\n",
    "predictions = model.predict(X_val)\n",
    "\n",
    "# Evaluation of model\n",
    "accuracy = accuracy_score(y_val, predictions)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "f1_DT = f1_score(y_val, predictions, average='micro')\n",
    "print(f'F1 Score on Validation Set: {f1_DT}')\n",
    "\n",
    "scores = cross_val_score(model, features, labels, cv=4)\n",
    "print(f'Cross Validation Scores: {scores}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ebfc98",
   "metadata": {},
   "source": [
    "With the RandomForest we were able to increase the training accuracy to 92%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b35ec16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9263502454991817\n",
      "F1 Score on Validation Set: 0.9263502454991817\n",
      "Cross Validation Scores: [0.90432503 0.92529489 0.92529489 0.92267366]\n"
     ]
    }
   ],
   "source": [
    "# Choose Random Forest as a model and train it\n",
    "model = RandomForestClassifier(random_state=42, n_estimators=200)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions on the val set\n",
    "predictions = model.predict(X_val)\n",
    "\n",
    "# Evaluation of model\n",
    "accuracy = accuracy_score(y_val, predictions)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "f1_DT = f1_score(y_val, predictions, average='micro')\n",
    "print(f'F1 Score on Validation Set: {f1_DT}')\n",
    "\n",
    "scores = cross_val_score(model, features, labels, cv=4)\n",
    "print(f'Cross Validation Scores: {scores}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8097d55",
   "metadata": {},
   "source": [
    "For the following changes we were not able to increase our training accuracy. In return they improved our testing accuracy on kaggle and therefore also our model. Firstly we performed hyperparameter tuning using GridSearchCV on the RandomForest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc6198b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9263502454991817\n",
      "F1 Score on Validation Set: 0.9263502454991817\n",
      "Cross Validation Scores: [0.90432503 0.92529489 0.92529489 0.92267366]\n"
     ]
    }
   ],
   "source": [
    "# Choose a model and train it\n",
    "model = RandomForestClassifier(random_state=42, n_estimators=200)\n",
    "\n",
    "# Hyperparameter tuning using GridSearchCV\n",
    "param_grid = {'n_estimators': [100, 150, 200], 'max_depth': [None, 10, 20]}\n",
    "grid_search = GridSearchCV(model, param_grid, cv=4)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Use the best model for predictions\n",
    "predictions = best_model.predict(X_val)\n",
    "\n",
    "# Evaluation of model\n",
    "accuracy = accuracy_score(y_val, predictions)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "f1_DT = f1_score(y_val, predictions, average='micro')\n",
    "print(f'F1 Score on Validation Set: {f1_DT}')\n",
    "\n",
    "scores = cross_val_score(best_model, features, labels, cv=4)\n",
    "print(f'Cross Validation Scores: {scores}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81951d2c",
   "metadata": {},
   "source": [
    "Then we tested our model and plotted which features contributed the most to the prediction. \n",
    "(In another notebook) We did this with with the help of RandomForest feature importace we filtered out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf6a621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove 30% of least important features\n",
    "columns_to_remove = ['hk1_t5_Frequency', 'race_Zerg', 'hk9_t60_Frequency', 'hk5_t5_Frequency', 'hk7_t60_Frequency', 'hk7_t550_Frequency', 'hk9_t340_Frequency', 'hk0_t20_Frequency', 'hk6_t20_Frequency', 'base_t20_Frequency', 'hk8_t200_Frequency', 'hk7_t270_Frequency', 'hk9_t20_Frequency', 'base_t5_Frequency', 'hk9_t200_Frequency', 'hk7_t340_Frequency', 'singleMineral_t550_Frequency', 'singleMineral_t200_Frequency', 'singleMineral_t340_Frequency', 'hk9_t270_Frequency', 'sFrequency', 'hk8_t100_Frequency', 'hk0_t5_Frequency', 'race_Terran', 'singleMineralFrequency', 'hk7_t20_Frequency', 'singleMineral_t270_Frequency', 'singleMineral_t100_Frequency', 'hk8_t60_Frequency', 'hk8_t20_Frequency', 'singleMineral_t60_Frequency', 'hk6_t5_Frequency', 'hk7_t5_Frequency', 'hk8_t5_Frequency', 'singleMineral_t20_Frequency', 'singleMineral_t5_Frequency']\n",
    "# Remove columns from DataFrame\n",
    "train_data_new = train_data_new.drop(columns=columns_to_remove)\n",
    "\n",
    "# Saving them in a csv file\n",
    "train_data_new.to_csv('actiontype_count.csv', index=False)\n",
    "\n",
    "train_data_new.head()\n",
    "\n",
    "# Target\n",
    "labels = train_data_new['PlayerID']\n",
    "\n",
    "# Keep only the columns we need as features\n",
    "features = train_data_new.drop(['PlayerID'], axis=1)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Choose a model and train it\n",
    "model = RandomForestClassifier(random_state=42, n_estimators=200)\n",
    "\n",
    "# Hyperparameter tuning using GridSearchCV\n",
    "param_grid = {'n_estimators': [100, 150, 200], 'max_depth': [None, 10, 20]}\n",
    "grid_search = GridSearchCV(model, param_grid, cv=4)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Use the best model for predictions\n",
    "predictions = best_model.predict(X_val)\n",
    "\n",
    "# Evaluation of model\n",
    "accuracy = accuracy_score(y_val, predictions)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "f1_DT = f1_score(y_val, predictions, average='micro')\n",
    "print(f'F1 Score on Validation Set: {f1_DT}')\n",
    "\n",
    "scores = cross_val_score(best_model, features, labels, cv=4)\n",
    "print(f'Cross Validation Scores: {scores}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14afbfd1",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "When given the test data we were looking at almost the same pattern as the training data: Each row was a gameplay with a race and the moves made. Just the identifaction of the player was missing. That one was for us to predict and to do so we used our pretrained model. \n",
    "\n",
    "### Precossesing\n",
    "\n",
    "But before, we had to change the data in the same way we did with the training data. We did this, so they would be able to compare.\n",
    "\n",
    "### Predicting \n",
    "\n",
    "The pre-trained model was then loaded and used to make predictions about the players.\n",
    "\n",
    "- Same preprocessing as training data to make it comparable\n",
    "- used pretrained model\n",
    "\n",
    "Afterwards we added some statistics to asses the testing performance. We wanted to see which predictions were made: ...\n",
    "\n",
    "And how many different players were predicted. We increased this score over time, because it meant our model was able differentiate better between players.\n",
    "\n",
    "- how many different players were predicted. we want a higher score because it can differentiate \n",
    "\n",
    "At the end we merged the predicted player IDs with the first row of the training data to obtain the corresponding player URLs.\n",
    "- Merge the predicted ID to get the url of the player"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79879abb",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "With our model we managed to reach a level of 82% testing accuracy and 92% training accuracy. \n",
    "\n",
    "- training and testing accuracy usually are not the same as in the testing part we try to predict our target from a completely new dataset, which proposes also new features.\n",
    "- \n",
    "\n",
    "### Improvements\n",
    "We could make some improvements to outr code by doing:\n",
    "- Feature Engineering:\n",
    "    We should consider additional features or transformations that might better capture the characteristics of our data and experiment with different aggregations, scaling, or encoding techniques.\n",
    "    An other thing to do could be to check for highly correlated features and trying top remove the correlated features to reduce multicollinearity.\n",
    "- Model Selection:\n",
    "    A part from the model already used, we could experiment with different machine learning models, that combines the results of other models, in order to obtain better results. Some examples could be Gradient Boosting, Support Vector Machines, or Neural Networks, which may capture complex patterns in the data.\n",
    "- Feature Importance:\n",
    "    Another improvement could be analyze the feature importances provided by the model, so to understand which features are contributing the most to the predictions, and use this data to clean our dataset and use the features with highest importance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
